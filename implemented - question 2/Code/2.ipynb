{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "from operator import getitem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './HW1-Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(pth):\n",
    "    return pd.read_csv(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data as pandas data frame\n",
    "org_data = read_file(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preproccess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "org_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values\n",
    "procceessed_data = org_data.replace({'Taste': { 0 : \"Bad\" , 1 : \"Good\"} , 'Odor': { 0 : \"Bad\" , 1 : \"Good\"} ,\n",
    "                                    'Fat ': { 0 : \"Low\" , 1 : \"High\"} , 'Turbidity': { 0 : \"Low\" , 1 : \"High\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Temprature</th>\n",
       "      <th>Taste</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Grade (target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>254</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>36</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>253</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>246</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.5</td>\n",
       "      <td>34</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>255</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>37</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "      <td>255</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pH  Temprature Taste  Odor  Fat  Turbidity  Colour Grade (target)\n",
       "0  6.6          35  Good   Bad  High       Low     254           high\n",
       "1  6.6          36   Bad  Good   Low      High     253           high\n",
       "2  8.5          70  Good  Good  High      High     246            low\n",
       "3  9.5          34  Good  Good   Low      High     255            low\n",
       "4  6.6          37   Bad   Bad   Low       Low     255         medium"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data after preproccess\n",
    "procceessed_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Train , Test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to train and test data\n",
    "\n",
    "train , test = train_test_split(procceessed_data , test_size=0.1 , random_state=1 , shuffle= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation to find best parameters\n",
    "\n",
    "t_train , t_valid = train_test_split(train , test_size=0.1 , random_state=1 , shuffle= True )\n",
    "\n",
    "t_train = t_train.to_numpy()\n",
    "t_valid = t_valid.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy values\n",
    "train = train.to_numpy()\n",
    "test  = test.to_numpy()\n",
    "\n",
    "# save columns name\n",
    "columns = org_data.columns.to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,train_data,test_data,features,criterion,pruning=None,max_depth=5,min_data = 10,post_peruning_perc=0.1):\n",
    "        \n",
    "        #check measure Parameter\n",
    "        if(criterion != \"entropy\" and criterion != \"gini\"):\n",
    "            raise \"invalid parameter for criterion\"\n",
    "        \n",
    "        #check pruning parameter\n",
    "        if(pruning != \"pre\" and pruning != \"post\" and pruning != None):\n",
    "            raise \"invalid parameter for pruning\"\n",
    "        \n",
    "        if( post_peruning_perc > 1 or post_peruning_perc < 0):\n",
    "            raise \"post_peruning_perc must be between 0 and 1\"\n",
    "\n",
    "        # class variables\n",
    "        self.train_data = copy.deepcopy(train_data) # train set\n",
    "        self.test_data  = copy.deepcopy(test_data) # test set\n",
    "        self.max_depth  = max_depth # maximum depth in pre_pruning\n",
    "        self.min_data   = min_data  # minimum branch data remaining in pre pruning\n",
    "        self.features = copy.deepcopy(features) # data features ( columns )\n",
    "        self.classes = list(np.unique(train_data[:,-1])) # classes ( targets )\n",
    "        self.pruning = 1 if(pruning == \"pre\") else 2 if(pruning == \"post\") else None # set pruning mode\n",
    "        self.tree = {} # final result ( tree )\n",
    "        self.confusion_matrix = np.zeros((len(self.classes) , len(self.classes)+1)) # confusion matrix of test data ; +1 for not seen branch\n",
    "        self.branching_criterion = self.Entropy if(criterion == \"entropy\") else self.Gini_index # set measure function\n",
    "        self.post_pruning_number = post_peruning_perc * self.train_data.shape[0] # minimum number of data should be pruned in post pruning mode\n",
    "        self.rules = [] # extracted rules\n",
    "\n",
    "        # check type of features value\n",
    "        temp = train_data[0]\n",
    "        for i in range(len(temp)):\n",
    "            if(type(temp[i]) != str and type(temp[i]) != int and type(temp[i]) != float):\n",
    "                raise f\"invalid type for {self.features[i]}\"\n",
    "            \n",
    "            \n",
    "    def Entropy(self,data):\n",
    "        #calculate entropy of this branch ( data )\n",
    "\n",
    "        _ , count = np.unique(data[:,-1],return_counts=True) # count number of data per each final class\n",
    "        count = count / np.sum(count) # probability of each class in this branch \n",
    "        entropy = np.multiply(count,np.log2(count)) # entropy of each class in this branch\n",
    "        total_entropy = -np.sum(entropy) # entropy of branch\n",
    "        return total_entropy\n",
    "\n",
    "\n",
    "    def Gini_index(self,data):\n",
    "        #calculate gini index of this branch ( data )\n",
    "\n",
    "        _ , count = np.unique(data[:,-1],return_counts=True)\n",
    "        count = count / np.sum(count) # probability of each class in this branch\n",
    "        p = np.power(count,2)\n",
    "        gini = 1 - np.sum(p)\n",
    "        return gini\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        columns = [i for i in range(self.train_data.shape[1]-1)] # array of remaining columns ; in the begining : all columns\n",
    "        self.create_tree(self.train_data,[],self.pruning==1,columns) # start bbuild tree\n",
    "        \n",
    "        # for post pruning\n",
    "        if(self.pruning == 2):\n",
    "            self.post_pruning()\n",
    "    \n",
    "\n",
    "    def create_tree(self,data,rule,prepruning,columns):\n",
    "        \"\"\"\n",
    "        function parameters :\n",
    "        data : current branch data\n",
    "        rule : current path in tree => [key1 , value1 , key2 , value2 , ...]\n",
    "        prepruning : flag of pre_pruning\n",
    "        columns : remaining feature for branching\n",
    "\n",
    "        creat_tree works recursively.\n",
    "        branching stop condition : prepruning conditions or pure branch\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #   create a copy of remaning features\n",
    "        column = copy.deepcopy(columns)\n",
    "        # number of data in this branch\n",
    "        data_size = data.shape[0]\n",
    "\n",
    "        # branch is pure\n",
    "        if(data_size <= 1 or len(np.unique(data[:,-1])) == 1):\n",
    "            \n",
    "            # pure branch\n",
    "            res = {\"res\" : { \"type\" : \"resault\"  , \"result type\" : \"pure\" , \"class\" : data[0,-1] , \"count\" : int(data_size)} }\n",
    "\n",
    "            # add to tree\n",
    "            self.add_to_tree(rule,res)\n",
    "            \n",
    "            return True\n",
    "\n",
    "        if(prepruning):\n",
    "            # check pre-pruning conditions : maximum tree depth or minimum data for classify\n",
    "            if(len(columns) < data.shape[1] - 1 - self.max_depth or data_size < self.min_data):\n",
    "                \n",
    "                # additional information about this leaf\n",
    "                res = { \"type\" : \"resault\"  , \"result type\" : \"percentage\"}\n",
    "                tmp = {}\n",
    "                \n",
    "                # find percentage for each class in this branch\n",
    "                vals , count = np.unique(data[:,-1] , return_counts=True)\n",
    "\n",
    "                for i in range(len(vals)):\n",
    "                    tmp[vals[i]] = {\n",
    "                        \"class\" : vals[i] ,\n",
    "                        \"count\" : count[i] ,\n",
    "                        \"percentage\" : round(count[i]/np.sum(count)*100)\n",
    "                    }\n",
    "                res[\"res\"] = tmp\n",
    "\n",
    "                # add to tree\n",
    "                self.add_to_tree(rule,res)   \n",
    "                return True\n",
    "            \n",
    "        if(len(column) == 0):\n",
    "            # not any more feature\n",
    "\n",
    "            # calc result for each classes\n",
    "\n",
    "            # additional information about this leaf\n",
    "            res = { \"type\" : \"resault\"  , \"result type\" : \"percentage\"}\n",
    "            tmp = {}\n",
    "            \n",
    "            # find percentage for each class in this branch\n",
    "            vals , count = np.unique(data[:,-1] , return_counts=True)\n",
    "\n",
    "            for i in range(len(vals)):\n",
    "                tmp[vals[i]] = {\n",
    "                    \"class\" : vals[i] ,\n",
    "                    \"count\" : count[i] ,\n",
    "                    \"percentage\" : round(count[i]/np.sum(count)*100)\n",
    "                }\n",
    "            res[\"res\"] = tmp\n",
    "\n",
    "            # add to tree\n",
    "            self.add_to_tree(rule,res)\n",
    "            return True\n",
    "        \n",
    "        # continue branching\n",
    "\n",
    "        # local variable; find best feature to split data\n",
    "\n",
    "        best_measure = 10000 # best measure value \n",
    "        best_index   = -1 # best feature index\n",
    "        branch_value_index = -1 # if best feature numeric  = > should save value of split point\n",
    "\n",
    "        # check diffrente columns for best result\n",
    "        for i in column:\n",
    "            # feature type\n",
    "            column_type = type(data[0,i])\n",
    "            # sort data according to this feature\n",
    "            sorted_data = data[data[:,i].argsort()]\n",
    "\n",
    "            # for nominal data\n",
    "            if(column_type == str):\n",
    "                # split data to sub branchs\n",
    "                splited_data = np.split(sorted_data[:,:], np.unique(sorted_data[:,i], return_index=True)[1][0:])[1:]\n",
    "\n",
    "                branching_measure = 0 # measure value calculated for split according to this feature\n",
    "\n",
    "                # calc measure for each sub branch ; then calculate weighted value of measure\n",
    "                for branch in splited_data:\n",
    "                    if(len(branch) > 0):\n",
    "                        try:\n",
    "                            branching_measure += (branch.shape[0] / data_size) * self.branching_criterion(branch)\n",
    "                        except:\n",
    "                            pass\n",
    "                # is better feature for branching ?\n",
    "                if(branching_measure < best_measure):\n",
    "                    best_measure = branching_measure\n",
    "                    best_index   = i\n",
    "            \n",
    "            # for numeric data\n",
    "            else:\n",
    "                # calculate measure for each possible splited branches\n",
    "                for j in range(1,data_size-1):\n",
    "\n",
    "                    # split data to 2 branch\n",
    "                    branch1 = sorted_data[:j,:]\n",
    "                    branch2 = sorted_data[j:,:]\n",
    "\n",
    "                    # calculate branching measur\n",
    "                    branching_measure = ((j/data_size) * self.branching_criterion(branch1)) + ((len(branch2)/data_size) * self.branching_criterion(branch2))\n",
    "\n",
    "                    # is better feature for branching ?\n",
    "                    if(branching_measure < best_measure):\n",
    "                        best_measure = branching_measure\n",
    "                        best_index   = i\n",
    "                        branch_value_index = j\n",
    "\n",
    "        # if there is a feature that split data\n",
    "        if(best_index != -1):\n",
    "            \n",
    "            # type of feature values\n",
    "            column_type = type(data[0,best_index])\n",
    "            # sort data according to this feature\n",
    "            sorted_data = data[data[:,best_index].argsort()]\n",
    "\n",
    "            # for naminal features\n",
    "            if(column_type == str):\n",
    "                # split data to branches according to best feature\n",
    "                splited_data = np.split(sorted_data[:,:], np.unique(sorted_data[:,best_index], return_index=True)[1][0:])[1:]\n",
    "\n",
    "                # for nominal features we should remove this feature from search domain\n",
    "                column.remove(best_index)\n",
    "\n",
    "                # calculate tree for each branches\n",
    "                for branch in splited_data:\n",
    "                    # check branch hasdata\n",
    "                    if(len(branch) > 0):\n",
    "                        val = branch[0,best_index]\n",
    "                        \n",
    "                        # add selected feature to rules\n",
    "                        next_rule = copy.deepcopy(rule)\n",
    "                        next_rule.append(self.features[best_index])\n",
    "                        next_rule.append(val)\n",
    "\n",
    "                        self.create_tree(branch,next_rule,prepruning,column)\n",
    "                return True\n",
    "\n",
    "            # for numeric features\n",
    "            else:\n",
    "                # split data to 2 branches according to best value of this feature\n",
    "                branch1 = sorted_data[:branch_value_index,:]\n",
    "                branch2 = sorted_data[branch_value_index:,:]\n",
    "\n",
    "                # calculate split value\n",
    "                val = (sorted_data[branch_value_index,best_index] + sorted_data[branch_value_index-1,best_index] ) / 2\n",
    "\n",
    "                # check branch has data\n",
    "\n",
    "                if(len(branch1) > 0):\n",
    "\n",
    "                    # add this feature to rules\n",
    "                    next_rule = copy.deepcopy(rule)\n",
    "                    next_rule.append(self.features[best_index])\n",
    "                    next_rule.append(f\"{val} >\")\n",
    "\n",
    "                    self.create_tree(branch1,next_rule,prepruning,column)\n",
    "\n",
    "                if(len(branch2)>0):\n",
    "\n",
    "                    # add this feature to rules\n",
    "                    next_rule = copy.deepcopy(rule)\n",
    "                    next_rule.append(self.features[best_index])\n",
    "                    next_rule.append(f\"{val} <\")\n",
    "\n",
    "                    \n",
    "                    self.create_tree(branch2,next_rule,prepruning,column)\n",
    "                return True\n",
    "            \n",
    "        # if there is not any feature that split data \n",
    "        else:\n",
    "            # can't find branching feature\n",
    "            # add current state as leaf\n",
    "            # calc result for each classes\n",
    "\n",
    "            # additional information about this leaf\n",
    "            res = {     \"type\" : \"resault\"  , \"result type\" : \"percentage\"}\n",
    "            tmp = {}\n",
    "            \n",
    "            # find percentage for each class in this branch\n",
    "            vals , count = np.unique(data[:,-1] , return_counts=True)\n",
    "\n",
    "            for i in range(len(vals)):\n",
    "                tmp[vals[i]] = {\n",
    "                    \"class\" : vals[i] ,\n",
    "                    \"count\" : int(count[i]) ,\n",
    "                    \"percentage\" : round(count[i]/np.sum(count)*100)\n",
    "                }\n",
    "            res[\"res\"] = tmp\n",
    "\n",
    "            # add to tree\n",
    "            self.add_to_tree(rule,res)\n",
    "            return True\n",
    "    \n",
    "    # add leafs to tree\n",
    "    def add_to_tree(self,rule,res):\n",
    "        # recursively create dictionary until tree contain remaining path\n",
    "        pth = res\n",
    "        while(True):\n",
    "            # try add leaf to tree\n",
    "            try:\n",
    "                reduce(getitem,rule[:-1],self.tree)[rule[-1]] = pth\n",
    "                break\n",
    "            # pathnot built ; 1 step goes back\n",
    "            except:\n",
    "                pth = {rule[-1] : pth}\n",
    "                rule.pop()\n",
    "\n",
    "    # post pruning of tree\n",
    "    def post_pruning(self):\n",
    "\n",
    "        # number of pruned data\n",
    "        n = 0\n",
    "\n",
    "        # make rules empty\n",
    "        self.rules = []\n",
    "\n",
    "        # extract rules from tree\n",
    "        self.extract_rules(copy.deepcopy(self.tree),[])\n",
    "        rules = self.rules\n",
    "        # sort rules by number of rule data\n",
    "        num = [np.sum(x[-1]) if (type(x[-1]) == list) else x[-1] for x in rules]\n",
    "        rules = [x for _,x in sorted(zip(num,rules))]\n",
    "\n",
    "        # prun to reach correct number of pruned data\n",
    "        while (n < self.post_pruning_number):\n",
    "\n",
    "            # number of data in each class after pruned\n",
    "            count = [0 for i in range(len(self.classes))]\n",
    "\n",
    "            # get rule with minimum number of data\n",
    "            prun = rules[0]\n",
    "            # extract rule path\n",
    "            rl = prun[:-3]\n",
    "\n",
    "            # find other rules in this path\n",
    "            prun_arr = []\n",
    "            for r in rules:\n",
    "                if(r[:len(rl)] == rl):\n",
    "                    prun_arr.append(r)\n",
    "                    \n",
    "            # remove rules of this path and count number of data in each class\n",
    "            for r in prun_arr:\n",
    "                rules.remove(r)\n",
    "                if(type(r[-2]) != list):\n",
    "                    count[self.classes.index(r[-2])] += int(r[-1])\n",
    "                else:\n",
    "                    for i in range(len(r[-1])):\n",
    "                        count[i] += int(r[-1][i])\n",
    "            \n",
    "            # add pruned number to n\n",
    "            n += np.sum(count)\n",
    "\n",
    "            # build new rule\n",
    "            rl.append(\"res\")\n",
    "            rl.append(self.classes)\n",
    "            rl.append(count)\n",
    "            rules.append(rl)\n",
    "\n",
    "            # sort rules for next prun step\n",
    "            num = [np.sum(x[-1]) if (type(x[-1]) == list) else x[-1] for x in rules]\n",
    "            rules = [x for _,x in sorted(zip(num,rules))]\n",
    "\n",
    "        # clear tree \n",
    "        self.tree = {}\n",
    "        for r in rules:\n",
    "            # path of rule\n",
    "            pth = r[:-3]\n",
    "\n",
    "            # pure rule\n",
    "            if(type(r[-2]) != list):\n",
    "                res = {\"res\" : { \"type\" : \"resault\"  , \"result type\" : \"pure\" , \"class\" : r[-2] , \"count\" : int(r[-1])} }\n",
    "            # pure rule           \n",
    "            elif(np.sum(r[-1]) == np.max(r[-1])):\n",
    "                idx = np.argmax(r[-1])\n",
    "                res = {\"res\" : { \"type\" : \"resault\"  , \"result type\" : \"pure\" , \"class\" : r[-2][idx] , \"count\" : int(np.max(r[-1]))} }\n",
    "            # percentage rule\n",
    "            else:\n",
    "                res = {     \"type\" : \"resault\"  , \"result type\" : \"percentage\"}\n",
    "                tmp = {}\n",
    "                for i in range(len(r[-2])):\n",
    "                    c = r[-2][i]\n",
    "                    count = r[-1][i]\n",
    "                    tmp[c] = {\n",
    "                        \"class\" : c,\n",
    "                        \"count\" : int(count),\n",
    "                        \"percentage\" : round(count / np.sum(r[-1])),\n",
    "                    }\n",
    "                res[\"res\"] = tmp\n",
    "            self.add_to_tree(pth,res)\n",
    "    \n",
    "    # extract rules from tree\n",
    "    def extract_rules(self,tree,rule):\n",
    "        key = list(tree.keys())[0]\n",
    "        # leaf \n",
    "        if(key == \"res\" or key == \"type\"):\n",
    "            # pure leaf\n",
    "            if(key == \"res\"):\n",
    "\n",
    "                res = tree[\"res\"]\n",
    "                rule.append(key)\n",
    "                rule.append(res[\"class\"])\n",
    "                rule.append(res[\"count\"])\n",
    "                self.rules.append(rule)\n",
    "\n",
    "            # percentage rule\n",
    "            else:\n",
    "                res = tree[\"res\"]\n",
    "                keys = list(res.keys())\n",
    "                for key in keys:\n",
    "                    final_rule = copy.deepcopy(rule)\n",
    "                    final_rule.append(\"res\")\n",
    "                    final_rule.append(key)\n",
    "                    final_rule.append(res[key][\"count\"])\n",
    "                    self.rules.append(final_rule)\n",
    "                    \n",
    "        # middle node        \n",
    "        else :\n",
    "            tree = tree[key]\n",
    "            vals = list(tree.keys())\n",
    "            for val in vals:\n",
    "                t = tree[val]\n",
    "                next_rule = copy.deepcopy(rule)\n",
    "                next_rule.append(key)\n",
    "                next_rule.append(val)\n",
    "                self.extract_rules(t,next_rule)\n",
    "\n",
    "\n",
    "    # calculate evaluation value for this tree and print all of them\n",
    "    def evaluate_results(self):\n",
    "        # true positive\n",
    "        TP = 0\n",
    "        # all data\n",
    "        all_data = np.sum(self.confusion_matrix)\n",
    "\n",
    "        # add correct estimated value to TP\n",
    "        for i in range(len(self.classes)):\n",
    "            TP += self.confusion_matrix[i,i]\n",
    "\n",
    "        # calculate precision , recall and f1 score of each classes\n",
    "        precisions = []\n",
    "        recalls    = []\n",
    "        f1 = []\n",
    "        for i in range(len(self.classes)):\n",
    "            precisions.append(self.confusion_matrix[i][i] / np.sum(self.confusion_matrix[i,:]))\n",
    "            recalls.append(self.confusion_matrix[i][i] / np.sum(self.confusion_matrix[:,i]))\n",
    "            f1.append((2*precisions[-1]*recalls[-1])/(precisions[-1]+recalls[-1]))\n",
    "        # micro precision , recall , f1 , accuracy\n",
    "        micro_measure = TP / all_data\n",
    "        # macro precision\n",
    "        macro_precision = np.sum(precisions) / len(precisions)\n",
    "        # macro recall\n",
    "        macro_recall = np.sum(recalls) / len(recalls)\n",
    "        # macro f1\n",
    "        macro_f1 = (2*macro_precision*macro_recall)/(macro_precision+macro_recall)\n",
    "        # macro accuracy\n",
    "        macro_accuracy = TP / all_data\n",
    "\n",
    "        # print confiusion matrix\n",
    "        print(\"\\t\",end=\"\")\n",
    "        for i in range(len(self.classes)):\n",
    "            print(f\"{self.classes[i]}\\t\",end=\"\")\n",
    "        print(\"not seen\")\n",
    "        for i in range(len(self.classes)):\n",
    "            print(f\"{self.classes[i]}\\t\",end=\"\")\n",
    "            for j in range(len(self.classes)+1):\n",
    "                print(f\"{round(self.confusion_matrix[i][j],2)}\\t\",end=\"\")\n",
    "            print(\"\")\n",
    "        print(\"____________________________________________\")\n",
    "            \n",
    "\n",
    "        # print each class precision , recall and f1_score\n",
    "        for i in range(len(self.classes)):\n",
    "            print(f\"{self.classes[i]}\\t( precision = {precisions[i]} , recall = {recalls[i]} , f1_score = {f1[i]} )\" , )\n",
    "\n",
    "        # print micro scope evaluation measures\n",
    "        print(f\"\\nmicro precision = {micro_measure}\")\n",
    "        print(f\"micro recall    = {micro_measure}\")\n",
    "        print(f\"micro f1_score  = {micro_measure}\")\n",
    "        print(f\"micro accuracy  = {micro_measure}\\n\")\n",
    "\n",
    "        # print macro scope evaluation measure\n",
    "        print(f\"macro precision = {macro_precision}\")\n",
    "        print(f\"macro recall    = {macro_recall}\")\n",
    "        print(f\"macro f1_score  = {macro_f1}\")\n",
    "        print(f\"macro accuracy  = {macro_accuracy}\")\n",
    "        \n",
    "    # test data with calculated tree\n",
    "    def test(self):\n",
    "        # traverse tree per test data\n",
    "        for data in self.test_data:\n",
    "\n",
    "            # copy tree in local variable\n",
    "            tree = self.tree\n",
    "            # target class of this test data\n",
    "            d_class = data[-1]\n",
    "            # index of target class \n",
    "            c_idx = self.classes.index(d_class)\n",
    "\n",
    "            # traverse tree\n",
    "            # flag : check traverse is over or not\n",
    "            flag = 1\n",
    "            while(flag):\n",
    "                # res => leaf \n",
    "                # if tree contain res key => we have a leaf\n",
    "                if(list(tree.keys()).count(\"res\") != 0):\n",
    "                    # get leaf values\n",
    "                    tree = tree[\"res\"]\n",
    "                    \n",
    "                    # for impure leafs\n",
    "                    if(list(tree.keys()).count(\"class\") == 0):\n",
    "                        # classes in leaf\n",
    "                        classes = list(tree.keys())\n",
    "                        # data belong to these classes sharedly ; add percentage of each class to confiusion matrix\n",
    "                        for c in classes:\n",
    "                            perc = tree[c][\"percentage\"] / 100 \n",
    "                            idx = self.classes.index(c)\n",
    "                            self.confusion_matrix[idx][c_idx] += perc\n",
    "                    # for pure leafs\n",
    "                    else :\n",
    "                        c = tree[\"class\"]\n",
    "                        idx = self.classes.index(c)\n",
    "                        self.confusion_matrix[idx][c_idx] += 1\n",
    "                    \n",
    "                    # traverse is over\n",
    "                    flag = 0\n",
    "                \n",
    "                # need more traverse\n",
    "                else:\n",
    "                    # print(tree)\n",
    "                    # get branching feature\n",
    "                    feature = list(tree.keys())[0]\n",
    "                    # traverse tree\n",
    "                    tree = tree[feature]\n",
    "                    # index of branching feature\n",
    "                    idx = self.features.index(feature)\n",
    "                    # value of current test data in branching feature\n",
    "                    val = data[idx]\n",
    "                    # type of feature value\n",
    "                    data_type = type(val)\n",
    "                    # for nominal features\n",
    "                    if(data_type == str):\n",
    "                        try :\n",
    "                            # in train proccess this path is seen\n",
    "                            tree = tree[val]\n",
    "                        except:             \n",
    "                            # in train procces this path is unssen           \n",
    "                            self.confusion_matrix[-1][c_idx]+= 1\n",
    "                            break\n",
    "\n",
    "                    # for numeric features\n",
    "                    else:\n",
    "\n",
    "                        keys = list(tree.keys())\n",
    "                        # value of branching\n",
    "                        split_val = float(keys[0].split(' ')[0])\n",
    "                        # check test data value is bigger than or less/equal to split val\n",
    "                        char = \"<\" if(val > split_val) else \">\"\n",
    "                        for key in keys:\n",
    "                            # find branching path\n",
    "                            if(key.find(char) != -1):\n",
    "                                tree = tree[key]\n",
    "                                break\n",
    "    \n",
    "    # save tree as json file\n",
    "    def save_as_json(self,pth):\n",
    "        with open(pth, 'w') as fp:\n",
    "            json.dump(self.tree, fp , default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t15.0\t0.0\t0.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t4.0\t0.0\t30.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 0.7894736842105263 , f1_score = 0.8823529411764706 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 0.8823529411764706 , recall = 1.0 , f1_score = 0.9375 )\n",
      "\n",
      "micro precision = 0.9583333333333334\n",
      "micro recall    = 0.9583333333333334\n",
      "micro f1_score  = 0.9583333333333334\n",
      "micro accuracy  = 0.9583333333333334\n",
      "\n",
      "macro precision = 0.9607843137254902\n",
      "macro recall    = 0.9298245614035089\n",
      "macro f1_score  = 0.9450509461426493\n",
      "macro accuracy  = 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "dt1 = DecisionTree(t_train,t_valid,columns,\"gini\")\n",
    "dt1.train()\n",
    "dt1.test()\n",
    "dt1.save_as_json(\"gini_complete.json\")\n",
    "dt1.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t19.0\t0.0\t2.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t28.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9047619047619048 , recall = 1.0 , f1_score = 0.9500000000000001 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 1.0 , recall = 0.9333333333333333 , f1_score = 0.9655172413793104 )\n",
      "\n",
      "micro precision = 0.9791666666666666\n",
      "micro recall    = 0.9791666666666666\n",
      "micro f1_score  = 0.9791666666666666\n",
      "micro accuracy  = 0.9791666666666666\n",
      "\n",
      "macro precision = 0.9682539682539683\n",
      "macro recall    = 0.9777777777777779\n",
      "macro f1_score  = 0.9729925684248686\n",
      "macro accuracy  = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "dt2 = DecisionTree(t_train,t_valid,columns,\"entropy\")\n",
    "dt2.train()\n",
    "dt2.test()\n",
    "dt2.save_as_json(\"entropy_complete.json\")\n",
    "dt2.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t14.98\t0.0\t0.36\t0.0\t\n",
      "low\t1.42\t47.0\t0.41\t0.0\t\n",
      "medium\t2.6\t0.0\t29.23\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9765319426336376 , recall = 0.7884210526315788 , f1_score = 0.8724519510774605 )\n",
      "low\t( precision = 0.962523039115298 , recall = 1.0 , f1_score = 0.9809036836063862 )\n",
      "medium\t( precision = 0.9183160540370721 , recall = 0.9743333333333334 , f1_score = 0.945495714054666 )\n",
      "\n",
      "micro precision = 0.9501041666666667\n",
      "micro recall    = 0.9501041666666667\n",
      "micro f1_score  = 0.9501041666666667\n",
      "micro accuracy  = 0.9501041666666667\n",
      "\n",
      "macro precision = 0.9524570119286692\n",
      "macro recall    = 0.9209181286549707\n",
      "macro f1_score  = 0.9364220865836711\n",
      "macro accuracy  = 0.9501041666666667\n"
     ]
    }
   ],
   "source": [
    "dt3 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"pre\",max_depth=4 , min_data=60)\n",
    "dt3.train()\n",
    "dt3.test()\n",
    "dt3.save_as_json(\"gini_prepruned_4_60.json\")\n",
    "dt3.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t17.37\t0.0\t2.61\t0.0\t\n",
      "low\t0.51\t47.0\t0.18\t0.0\t\n",
      "medium\t1.12\t0.0\t27.21\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.8693693693693694 , recall = 0.9142105263157894 , f1_score = 0.8912262698819907 )\n",
      "low\t( precision = 0.9855315579786119 , recall = 1.0 , f1_score = 0.9927130636814869 )\n",
      "medium\t( precision = 0.9604659371690787 , recall = 0.907 , f1_score = 0.9329675981484656 )\n",
      "\n",
      "micro precision = 0.9539583333333335\n",
      "micro recall    = 0.9539583333333335\n",
      "micro f1_score  = 0.9539583333333335\n",
      "micro accuracy  = 0.9539583333333335\n",
      "\n",
      "macro precision = 0.9384556215056866\n",
      "macro recall    = 0.9404035087719298\n",
      "macro f1_score  = 0.9394285554130813\n",
      "macro accuracy  = 0.9539583333333335\n"
     ]
    }
   ],
   "source": [
    "dt4 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"pre\",max_depth=4 , min_data=60)\n",
    "dt4.train()\n",
    "dt4.test()\n",
    "dt4.save_as_json(\"entropy_prepruned_4_60.json\")\n",
    "dt4.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t15.22\t0.0\t0.36\t0.0\t\n",
      "low\t1.42\t47.0\t0.41\t0.0\t\n",
      "medium\t2.36\t0.0\t29.23\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9768934531450578 , recall = 0.8010526315789473 , f1_score = 0.8802776171197223 )\n",
      "low\t( precision = 0.962523039115298 , recall = 1.0 , f1_score = 0.9809036836063862 )\n",
      "medium\t( precision = 0.9252928141817031 , recall = 0.9743333333333334 , f1_score = 0.9491800616983277 )\n",
      "\n",
      "micro precision = 0.9526041666666667\n",
      "micro recall    = 0.9526041666666667\n",
      "micro f1_score  = 0.9526041666666667\n",
      "micro accuracy  = 0.9526041666666667\n",
      "\n",
      "macro precision = 0.954903102147353\n",
      "macro recall    = 0.9251286549707602\n",
      "macro f1_score  = 0.939780106556452\n",
      "macro accuracy  = 0.9526041666666667\n"
     ]
    }
   ],
   "source": [
    "dt5 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"pre\",max_depth=6 , min_data=40)\n",
    "dt5.train()\n",
    "dt5.test()\n",
    "dt5.save_as_json(\"gini_prepruned_6_40.json\")\n",
    "dt5.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t17.87\t0.0\t3.63\t0.0\t\n",
      "low\t0.51\t47.0\t0.18\t0.0\t\n",
      "medium\t0.62\t0.0\t26.19\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.8311627906976744 , recall = 0.9405263157894735 , f1_score = 0.8824691358024692 )\n",
      "low\t( precision = 0.9855315579786119 , recall = 1.0 , f1_score = 0.9927130636814869 )\n",
      "medium\t( precision = 0.9768743006340918 , recall = 0.873 , f1_score = 0.9220207709910229 )\n",
      "\n",
      "micro precision = 0.9485416666666667\n",
      "micro recall    = 0.9485416666666667\n",
      "micro f1_score  = 0.9485416666666667\n",
      "micro accuracy  = 0.9485416666666667\n",
      "\n",
      "macro precision = 0.931189549770126\n",
      "macro recall    = 0.9378421052631577\n",
      "macro f1_score  = 0.9345039880984949\n",
      "macro accuracy  = 0.9485416666666667\n"
     ]
    }
   ],
   "source": [
    "dt6 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"pre\",max_depth=6 , min_data=40)\n",
    "dt6.train()\n",
    "dt6.test()\n",
    "dt6.save_as_json(\"entropy_prepruned_6_40.json\")\n",
    "dt6.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t14.5\t0.0\t0.0\t0.0\t\n",
      "low\t0.82\t47.0\t0.08\t0.0\t\n",
      "medium\t3.68\t0.0\t29.92\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 0.7631578947368421 , f1_score = 0.8656716417910448 )\n",
      "low\t( precision = 0.9812108559498957 , recall = 1.0 , f1_score = 0.9905163329820864 )\n",
      "medium\t( precision = 0.8904761904761905 , recall = 0.9973333333333334 , f1_score = 0.9408805031446541 )\n",
      "\n",
      "micro precision = 0.9522916666666666\n",
      "micro recall    = 0.9522916666666666\n",
      "micro f1_score  = 0.9522916666666666\n",
      "micro accuracy  = 0.9522916666666666\n",
      "\n",
      "macro precision = 0.9572290154753621\n",
      "macro recall    = 0.9201637426900584\n",
      "macro f1_score  = 0.938330490154921\n",
      "macro accuracy  = 0.9522916666666666\n"
     ]
    }
   ],
   "source": [
    "dt7 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"pre\",max_depth=8 , min_data=20)\n",
    "dt7.train()\n",
    "dt7.test()\n",
    "dt7.save_as_json(\"gini_prepruned_8_20.json\")\n",
    "dt7.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t18.49\t0.0\t2.0\t0.0\t\n",
      "low\t0.51\t47.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t28.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9023914104441191 , recall = 0.973157894736842 , f1_score = 0.9364396049632818 )\n",
      "low\t( precision = 0.9892654178067776 , recall = 1.0 , f1_score = 0.9946037456353825 )\n",
      "medium\t( precision = 1.0 , recall = 0.9333333333333333 , f1_score = 0.9655172413793104 )\n",
      "\n",
      "micro precision = 0.9738541666666666\n",
      "micro recall    = 0.9738541666666666\n",
      "micro f1_score  = 0.9738541666666666\n",
      "micro accuracy  = 0.9738541666666666\n",
      "\n",
      "macro precision = 0.9638856094169655\n",
      "macro recall    = 0.968830409356725\n",
      "macro f1_score  = 0.9663516838205937\n",
      "macro accuracy  = 0.9738541666666666\n"
     ]
    }
   ],
   "source": [
    "dt8 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"pre\",max_depth=8 , min_data=20)\n",
    "dt8.train()\n",
    "dt8.test()\n",
    "dt8.save_as_json(\"entropy_prepruned_8_20.json\")\n",
    "dt8.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t15.0\t0.0\t0.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t4.0\t0.0\t30.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 0.7894736842105263 , f1_score = 0.8823529411764706 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 0.8823529411764706 , recall = 1.0 , f1_score = 0.9375 )\n",
      "\n",
      "micro precision = 0.9583333333333334\n",
      "micro recall    = 0.9583333333333334\n",
      "micro f1_score  = 0.9583333333333334\n",
      "micro accuracy  = 0.9583333333333334\n",
      "\n",
      "macro precision = 0.9607843137254902\n",
      "macro recall    = 0.9298245614035089\n",
      "macro f1_score  = 0.9450509461426493\n",
      "macro accuracy  = 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "dt9 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"post\",post_peruning_perc=0.05)\n",
    "dt9.train()\n",
    "dt9.save_as_json(\"gini_post_5.json\")\n",
    "dt9.test()\n",
    "dt9.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t19.0\t0.0\t2.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t28.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9047619047619048 , recall = 1.0 , f1_score = 0.9500000000000001 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 1.0 , recall = 0.9333333333333333 , f1_score = 0.9655172413793104 )\n",
      "\n",
      "micro precision = 0.9791666666666666\n",
      "micro recall    = 0.9791666666666666\n",
      "micro f1_score  = 0.9791666666666666\n",
      "micro accuracy  = 0.9791666666666666\n",
      "\n",
      "macro precision = 0.9682539682539683\n",
      "macro recall    = 0.9777777777777779\n",
      "macro f1_score  = 0.9729925684248686\n",
      "macro accuracy  = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "dt10 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"post\",post_peruning_perc=0.05)\n",
    "dt10.train()\n",
    "dt10.test()\n",
    "dt10.save_as_json(\"entropy_post_5.json\")\n",
    "dt10.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t15.0\t0.0\t0.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t4.0\t0.0\t30.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 0.7894736842105263 , f1_score = 0.8823529411764706 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 0.8823529411764706 , recall = 1.0 , f1_score = 0.9375 )\n",
      "\n",
      "micro precision = 0.9583333333333334\n",
      "micro recall    = 0.9583333333333334\n",
      "micro f1_score  = 0.9583333333333334\n",
      "micro accuracy  = 0.9583333333333334\n",
      "\n",
      "macro precision = 0.9607843137254902\n",
      "macro recall    = 0.9298245614035089\n",
      "macro f1_score  = 0.9450509461426493\n",
      "macro accuracy  = 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "dt11 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"post\",post_peruning_perc=0.1)\n",
    "dt11.train()\n",
    "dt11.test()\n",
    "dt11.save_as_json(\"gini_post_10.json\")\n",
    "dt11.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t19.0\t0.0\t2.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t28.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9047619047619048 , recall = 1.0 , f1_score = 0.9500000000000001 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 1.0 , recall = 0.9333333333333333 , f1_score = 0.9655172413793104 )\n",
      "\n",
      "micro precision = 0.9791666666666666\n",
      "micro recall    = 0.9791666666666666\n",
      "micro f1_score  = 0.9791666666666666\n",
      "micro accuracy  = 0.9791666666666666\n",
      "\n",
      "macro precision = 0.9682539682539683\n",
      "macro recall    = 0.9777777777777779\n",
      "macro f1_score  = 0.9729925684248686\n",
      "macro accuracy  = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "dt12 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"post\",post_peruning_perc=0.1)\n",
    "dt12.train()\n",
    "dt12.test()\n",
    "dt12.save_as_json(\"entropy_post_10.json\")\n",
    "dt12.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t15.0\t0.0\t0.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t4.0\t0.0\t30.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 0.7894736842105263 , f1_score = 0.8823529411764706 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 0.8823529411764706 , recall = 1.0 , f1_score = 0.9375 )\n",
      "\n",
      "micro precision = 0.9583333333333334\n",
      "micro recall    = 0.9583333333333334\n",
      "micro f1_score  = 0.9583333333333334\n",
      "micro accuracy  = 0.9583333333333334\n",
      "\n",
      "macro precision = 0.9607843137254902\n",
      "macro recall    = 0.9298245614035089\n",
      "macro f1_score  = 0.9450509461426493\n",
      "macro accuracy  = 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "dt13 = DecisionTree(t_train,t_valid,columns,\"gini\",pruning=\"post\",post_peruning_perc=0.2)\n",
    "dt13.train()\n",
    "dt13.test()\n",
    "dt13.save_as_json(\"gini_post_20.json\")\n",
    "dt13.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t19.0\t0.0\t2.0\t0.0\t\n",
      "low\t0.0\t47.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t28.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 0.9047619047619048 , recall = 1.0 , f1_score = 0.9500000000000001 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 1.0 , recall = 0.9333333333333333 , f1_score = 0.9655172413793104 )\n",
      "\n",
      "micro precision = 0.9791666666666666\n",
      "micro recall    = 0.9791666666666666\n",
      "micro f1_score  = 0.9791666666666666\n",
      "micro accuracy  = 0.9791666666666666\n",
      "\n",
      "macro precision = 0.9682539682539683\n",
      "macro recall    = 0.9777777777777779\n",
      "macro f1_score  = 0.9729925684248686\n",
      "macro accuracy  = 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "dt14 = DecisionTree(t_train,t_valid,columns,\"entropy\",pruning=\"post\",post_peruning_perc=0.2)\n",
    "dt14.train()\n",
    "dt14.test()\n",
    "dt14.save_as_json(\"entropy_post_20.json\")\n",
    "dt14.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\thigh\tlow\tmedium\tnot seen\n",
      "high\t26.0\t0.0\t0.0\t0.0\t\n",
      "low\t0.0\t43.0\t0.0\t0.0\t\n",
      "medium\t0.0\t0.0\t37.0\t0.0\t\n",
      "____________________________________________\n",
      "high\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "low\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "medium\t( precision = 1.0 , recall = 1.0 , f1_score = 1.0 )\n",
      "\n",
      "micro precision = 1.0\n",
      "micro recall    = 1.0\n",
      "micro f1_score  = 1.0\n",
      "micro accuracy  = 1.0\n",
      "\n",
      "macro precision = 1.0\n",
      "macro recall    = 1.0\n",
      "macro f1_score  = 1.0\n",
      "macro accuracy  = 1.0\n"
     ]
    }
   ],
   "source": [
    "dt15 = DecisionTree(train,test,columns,\"entropy\")\n",
    "dt15.train()\n",
    "dt15.test()\n",
    "dt15.save_as_json(\"final.json\")\n",
    "dt15.evaluate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = org_data.replace({\"Grade (target)\" : {\"high\" : 2 , \"medium\" : 1 , \"low\" : 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "codded_data = pd.get_dummies(d).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.6,  35. ,   1. ,   0. ,   1. ,   0. , 254. ,   2. ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codded_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(codded_data[:,:-1],codded_data[:,-1] ,train_size= 0.9 , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "114067fc0f372de1d09e6032eb12f72f309396567ef129ebb31a527ac014185f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
